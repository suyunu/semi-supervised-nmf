{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One vs All Method\n",
    "\n",
    "Train NMF for each topic separately.\n",
    "\n",
    "Use all Wiki articles as Background Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burki\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "from omterms.interface import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import libs.synonyms as syn\n",
    "import libs.text_preprocess as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots and Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['universalism', 'hedonism', 'achievement', 'power',\n",
    "       'self-direction', 'benevolence', 'conformity', 'tradition', 'stimulation',\n",
    "       'security']\n",
    "\n",
    "schwartz =['universalism', 'benevolence', 'conformity', 'tradition',\n",
    "       'security', 'power', 'achievement', 'hedonism', 'stimulation',\n",
    "       'self-direction']\n",
    "\n",
    "def plot_radar_chart(doc_topic_cumul, doc, doc_names):\n",
    "    # ------- PART 1: Create background\n",
    " \n",
    "    # number of variablecategories\n",
    "    \n",
    "    \n",
    "    schwartz_dist = []\n",
    "    for sch in schwartz:\n",
    "        schwartz_dist.append(doc_topic_cumul[doc][categories.index(sch)])\n",
    "    \n",
    "    N = len(schwartz)\n",
    "    \n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], schwartz)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([25,50,75], [\"25\",\"50\",\"75\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0,100)\n",
    "\n",
    "\n",
    "    # ------- PART 2: Add plots\n",
    "\n",
    "    # Plot each individual = each line of the data\n",
    "    # I don't do a loop, because plotting more than 3 groups makes the chart unreadable\n",
    "\n",
    "    # Ind1\n",
    "    values = list(schwartz_dist) + list(schwartz_dist[:1])\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "    ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "    # Add legend\n",
    "    #plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(\"Schwartz Chart - \" + doc_names[doc])\n",
    "    plt.savefig(\"Schwartz_Chart_\" + str(doc))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "    \n",
    "def print_top_words(model, theme, tfidf_vectorizer, n_top_words, n_topics=3):\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    print(color.CYAN + color.BOLD + categories[theme] + color.END)\n",
    "    for topic_idx, topic in enumerate(model[theme].components_):\n",
    "        if topic_idx / n_topics == 1:\n",
    "            break\n",
    "        message = color.BOLD + \"Topic #%d: \" % topic_idx + color.END\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "def print_cumulative_train_doc_topics(data, doc_topic, doc, n_best):\n",
    "    test_theme = data.iloc[doc]['theme']\n",
    "    print(color.BOLD + \"Doc \" + str(doc) + color.RED +  \" (\" + test_theme + \")\\t: \" + color.END, end='')\n",
    "    dt = doc_topic[doc]\n",
    "    for i in dt.argsort()[:-n_best - 1:-1]:\n",
    "        print(\"(\", end='')\n",
    "        try:\n",
    "            print(color.CYAN + color.BOLD + categories[i] + color.END, end='')\n",
    "        except:\n",
    "            print(color.CYAN + color.BOLD + \"General\" + color.END, end='')\n",
    "        print(\", %d, %.2lf)  \" %(i, dt[i]), end='')    \n",
    "    print()\n",
    "    \n",
    "def print_cumulative_test_doc_topics(doc_topic, doc, n_best):\n",
    "    print(color.BOLD + \"Doc \" + str(doc) + \"\\t: \" + color.END, end='')\n",
    "    dt = doc_topic[doc]\n",
    "    for i in dt.argsort()[:-n_best - 1:-1]:\n",
    "        print(\"(\", end='')\n",
    "        try:\n",
    "            print(color.CYAN + color.BOLD + categories[i] + color.END, end='')\n",
    "        except:\n",
    "            print(color.CYAN + color.BOLD + \"General\" + color.END, end='')\n",
    "        print(\", %d, %.2lf)  \" %(i, dt[i]), end='')    \n",
    "    print()\n",
    "\n",
    "def print_doc_topics(doc_topic, doc, n_best):\n",
    "    print(color.BOLD + \"Doc \" + str(doc) + \"\\t: \" + color.END, end='')\n",
    "    for i in doc_topic[doc].argsort()[:-n_best - 1:-1]:\n",
    "        print(\"(\", end='')\n",
    "        try:\n",
    "            print(color.CYAN + color.BOLD + categories[i//3] + color.END, end='')\n",
    "        except:\n",
    "            print(color.CYAN + color.BOLD + \"General\" + color.END, end='')\n",
    "        print(\", %d, %.2lf)  \" %(i, doc_topic[doc][i]), end='')    \n",
    "    print()\n",
    "\n",
    "def print_train_results(doc_topic, doc, corpus, data):\n",
    "    print(color.BOLD + \"Document \" + str(doc) + color.END)\n",
    "    print()\n",
    "    print(color.BOLD + \"Text: \" + color.END)\n",
    "    print(\"...\" + corpus[doc][len(corpus[doc])//3:len(corpus[doc])//3+500] + \"...\")\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print(color.BOLD + \"Topic Distribution: \" + color.END)\n",
    "    #print(pd.DataFrame(data=[W_test_norm[doc]], index = [doc], columns=categories+['general']))\n",
    "    print_cumulative_train_doc_topics(data, doc_topic, doc, 11) \n",
    "    print()\n",
    "    \n",
    "    plot_radar_chart(doc_topic, doc)\n",
    "    \n",
    "    \n",
    "def print_test_results(doc, doc_topic, test_corpusPP, pre_nmf_list, pre_tfidf_vectorizer, word_topic_scores, word_topic_sp,\n",
    "                       corpus, doc_names, pre_trained_doc, purity_score, word_count, only_doc_words):\n",
    "    print(color.BOLD + \"Document \" + str(doc) + \": \" + doc_names[doc] + color.END)\n",
    "    #print()\n",
    "    #print(color.BOLD + \"Text: \" + color.END)\n",
    "    #print(\"...\" + corpus[doc][len(corpus[doc])//3:len(corpus[doc])//3+500] + \"...\")\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print(color.BOLD + \"Topic Distribution: \" + color.END)\n",
    "    \n",
    "    #print(pd.DataFrame(data=[W_test_norm[doc]], index = [doc], columns=categories+['general']))\n",
    "    print_cumulative_test_doc_topics(doc_topic, doc, 11)\n",
    "    print()\n",
    "    \n",
    "    plot_radar_chart(doc_topic, doc, doc_names)\n",
    "    print()\n",
    "    \n",
    "    df_scores = schwartz_word_scores(doc, W_test_norm, test_corpusPP, word_topic_scores, word_topic_sp, pre_tfidf_vectorizer, purity_score, word_count, only_doc_words)    \n",
    "    \n",
    "    display(df_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulate_W(W, n_topics):\n",
    "    W_cumul = []\n",
    "    for d in W:\n",
    "        temp = []\n",
    "        for i in range(W.shape[1]//n_topics):\n",
    "            temp.append(d[i*n_topics:(i+1)*n_topics].sum())\n",
    "        W_cumul.append(temp)\n",
    "\n",
    "    W_cumul = np.asarray(W_cumul)\n",
    "    \n",
    "    return W_cumul\n",
    "\n",
    "def normalize_W(W):\n",
    "    W_cumul_norm = W/(W.sum(axis=1).reshape(W.shape[0], 1))\n",
    "    W_cumul_norm *= 100\n",
    "    \n",
    "    return W_cumul_norm\n",
    "\n",
    "def prepare_export(W, docs, doc_names, filepath):\n",
    "    schwartz_dist = []\n",
    "    for doc in range(len(docs)):\n",
    "        temp_dist = []\n",
    "        for sch in schwartz:\n",
    "            temp_dist.append(W[doc][categories.index(sch)])\n",
    "        schwartz_dist.append(temp_dist)\n",
    "    schwartz_dist = np.asarray(schwartz_dist)\n",
    "    \n",
    "    df = pd.DataFrame(data=schwartz_dist,index = range(len(schwartz_dist)), columns=schwartz)\n",
    "    df['Text'] = docs\n",
    "    df[\"name\"] = doc_names\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def export_to_excel(W, docs, doc_names, filepath):\n",
    "    '''\n",
    "    Take cumulated W as input.\n",
    "    Don't forget to put xlsx as file extension '''\n",
    "    \n",
    "    df = prepare_export(W, docs, doc_names, filepath)\n",
    "    df.to_excel(filepath)\n",
    "    return df\n",
    "\n",
    "def export_to_csv(W, docs, doc_names, filepath):\n",
    "    '''\n",
    "    Take cumulated W as input.\n",
    "    Don't forget to put csv as file extension '''\n",
    "    \n",
    "    df = prepare_export(W, docs, doc_names, filepath)\n",
    "    df.to_csv(filepath)\n",
    "    return df\n",
    "\n",
    "def export_word_scores_excel(W_test_norm, W_test_list, doc_names, pre_trained_doc, filepath, purity_score=False, word_count=10, only_doc_words=False):\n",
    "    writer = pd.ExcelWriter(filepath, engine = 'xlsxwriter')\n",
    "    \n",
    "    pre_nmf_list, pre_tfidf_vectorizer = pickle.load( open( pre_trained_doc, \"rb\" ) )\n",
    "    word_topic_scores, word_topic_sp = calculate_word_topic_scores(pre_nmf_list, W_test_list)\n",
    "    \n",
    "    for i, dn in enumerate(doc_names):\n",
    "        df = schwartz_word_scores(i, W_test_norm, test_corpusPP, word_topic_scores, word_topic_sp, pre_tfidf_vectorizer, purity_score, word_count, only_doc_words)\n",
    "        dn = re.sub('[\\\\\\:/*?\\[\\]]', '', dn)\n",
    "        df.to_excel(writer, str(i)+'-'+dn[:25])\n",
    "        \n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "def export_doc_tfidf_scores(tfidf_test, doc_names, pre_trained_doc, filepath):\n",
    "    writer = pd.ExcelWriter(filepath, engine = 'xlsxwriter')\n",
    "    \n",
    "    pre_nmf_list, pre_tfidf_vectorizer = pickle.load( open( pre_trained_doc, \"rb\" ) )\n",
    "    \n",
    "    for i, dn in enumerate(doc_names):\n",
    "        word_list = []\n",
    "        tfidf_doc = tfidf_test[i].toarray()[0]\n",
    "        feature_names = pre_tfidf_vectorizer.get_feature_names()\n",
    "        for idx in list(reversed(tfidf_doc.argsort())):\n",
    "            if tfidf_doc[idx] < 0.0005:\n",
    "                break\n",
    "            word_list.append((feature_names[idx], np.round(tfidf_doc[idx], 3)))\n",
    "\n",
    "        dn = re.sub('[\\\\\\:/*?\\[\\]]', '', dn)\n",
    "        pd.DataFrame(word_list, columns=[\"Word\", \"tf-idf\"]).to_excel(writer, dn[:30])\n",
    "    \n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinksHTMLaref(page):\n",
    "    \"\"\"\n",
    "\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"a href=\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('\"', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1: end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "def getLinksHTML(page):\n",
    "    \"\"\"\n",
    "\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"href=\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('\"htt', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1: end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "def getLinksXML(page):\n",
    "    \"\"\"\n",
    "\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"<link/>\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('http', start_link)\n",
    "    end_quote = page.find('<', start_quote )\n",
    "    url = page[start_quote : end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "\n",
    "def extractFromURL(surl):\n",
    "    response = requests.get(surl)\n",
    "    # parse html\n",
    "    page = str(BeautifulSoup(response.content,\"lxml\"))\n",
    "    is_XML = surl.endswith('xml')\n",
    "    url_list = []\n",
    "    while True:\n",
    "        if is_XML:\n",
    "            url, n = getLinksXML(page)\n",
    "        else:\n",
    "            url, n = getLinksHTML(page)\n",
    "        \n",
    "        page = page[n:]\n",
    "        if url:\n",
    "            if set(url_list).intersection(set(url)) == set() or len(set(url_list).intersection(set(url))) != len(url):\n",
    "                url_list.append(url)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    page = str(BeautifulSoup(response.content,\"lxml\"))\n",
    "    stlink= surl.find(\"//\")\n",
    "    stlink= surl.find(\"/\",stlink+2 )\n",
    "    base = surl[0:stlink]\n",
    "    while True:\n",
    "        if is_XML:\n",
    "            break\n",
    "        else:\n",
    "            url, n = getLinksHTMLaref(page)\n",
    "        page = page[n:]\n",
    "        if url:\n",
    "            url = base+url\n",
    "            if set(url_list).intersection(set(url)) == set() or len(set(url_list).intersection(set(url))) != len(url):\n",
    "                url_list.append(url)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "    \n",
    "    PPcorpus = [' '.join(list((extract_terms(doc, extra_process = ['stem'])['Stem']+' ')*extract_terms(doc, \n",
    "                extra_process = ['stem'])['TF'])) if doc != '' else '' for doc in corpus]\n",
    "    return PPcorpus\n",
    "    \n",
    "def evaluate_docs(docs, nmf, tfidf_test, betaloss = 'kullback-leibler'):\n",
    "    X_test = tfidf_test\n",
    "    H_test = nmf.components_\n",
    "    \n",
    "    # Fit the NMF model\n",
    "    t0 = time()\n",
    "\n",
    "    W_test = nmf.transform(X_test)\n",
    "    \n",
    "    return W_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_topics(pretrained_filepath):\n",
    "    nmf_list, tfidf_vectorizer = pickle.load( open( pretrained_filepath, \"rb\" ) )\n",
    "    print(\"\\nTopics in NMF model:\")\n",
    "    for i in range(10):\n",
    "        print_top_words(nmf_list, i, tfidf_vectorizer, n_top_words=5, n_topics=3)\n",
    "\n",
    "def add_corpus_txt(filepath, test_corpus):\n",
    "    try:\n",
    "        f = open(filepath, \"r\")\n",
    "        txt = f.read()\n",
    "        test_corpus.append(txt)\n",
    "        f.close()\n",
    "    except:\n",
    "        test_corpus.append(\"\")\n",
    "        print(\"File not found - \" + filepath)\n",
    "\n",
    "\n",
    "def add_corpus_url(url, api_key, test_corpus):\n",
    "    insightIP = 'http://178.62.229.16'\n",
    "    insightPort = '8484'\n",
    "    insightVersion = 'v1.0'\n",
    "\n",
    "    insightSetting = insightIP + ':' + insightPort + '/api/' + insightVersion \n",
    "    request = '/text_analytics/url_scraper?' + 'url=' + url + '&' + 'api_key=' + api_key\n",
    "\n",
    "    # send a request\n",
    "    res = requests.get(insightSetting + request)\n",
    "    if \"Unauthorized Connection\" in res.json():\n",
    "        test_corpus.append(\"\")\n",
    "        print(res.json()[\"Unauthorized Connection\"] + \" - \" + url)\n",
    "    elif \"Error\" in res.json():\n",
    "        test_corpus.append(\"\")\n",
    "        print(res.json()[\"Error\"] + \" - \" + url)\n",
    "    elif \"text\" in res.json():\n",
    "        test_corpus.append(res.json()['text'])\n",
    "        if res.json()['text'] == \"\":\n",
    "            print(\"Empty text - \" + url)\n",
    "    else:\n",
    "        test_corpus.append(\"\")\n",
    "        print(\"Empty text - \" + url)\n",
    "    \n",
    "def evaluate_test_corpus(pretrained_filepath, test_corpus, word_replacements):\n",
    "    nmf_list, tfidf_vectorizer = pickle.load( open( pretrained_filepath, \"rb\" ) )\n",
    "    \n",
    "#     deprecated\n",
    "#     test_corpusPP = preprocess_corpus(test_corpus)\n",
    "#     tfidf_test = tfidf_vectorizer.transform(test_corpusPP)\n",
    "#     n_features = tfidf_test.shape[1]\n",
    "    \n",
    "    W_test_list = []\n",
    "    for i, nmf in enumerate(nmf_list):\n",
    "        docs = [syn.replace_synoyms(test_corpusPP[idx], word_replacements[idx][i]) for idx in range(len(test_corpusPP))]\n",
    "        tfidf_test = tfidf_vectorizer.transform(docs)\n",
    "        n_features = tfidf_test.shape[1]\n",
    "        \n",
    "        print(\"Fitting NMF for \" + str(categories[i]))\n",
    "        W_test = evaluate_docs(docs, nmf, tfidf_test, betaloss = 'kullback-leibler')\n",
    "        W_test_list.append(W_test)\n",
    "        \n",
    "    # Sum up sub topics\n",
    "    W_test_norm_list = []\n",
    "    for W in W_test_list:\n",
    "        W_test_cumul = cumulate_W(W, n_topics=3)\n",
    "        W_test_norm = normalize_W(W_test_cumul)\n",
    "        W_test_norm_list.append(W_test_norm)\n",
    "    W_test_norm = np.asarray(W_test_norm_list).T[0]\n",
    "    W_test_norm = np.nan_to_num(W_test_norm)\n",
    "\n",
    "    # cumulated-normalized and raw\n",
    "    return W_test_norm, np.asarray(W_test_list), tfidf_test\n",
    "\n",
    "def print_interactive_test_results(W_test_norm, W_test_list, test_corpus, test_corpusPP, doc_names, pre_trained_doc, purity_score, word_count, only_doc_words):\n",
    "    pre_nmf_list, pre_tfidf_vectorizer = pickle.load( open( pre_trained_doc, \"rb\" ) )\n",
    "    word_topic_scores, word_topic_sp = calculate_word_topic_scores(pre_nmf_list, W_test_list)\n",
    "    \n",
    "    interact(print_test_results,\n",
    "             doc = (0, len(W_test_norm)-1, 1),\n",
    "             doc_topic=fixed(W_test_norm),\n",
    "             test_corpusPP=fixed(test_corpusPP),\n",
    "             pre_nmf_list=fixed(pre_nmf_list),\n",
    "             pre_tfidf_vectorizer=fixed(pre_tfidf_vectorizer),\n",
    "             word_topic_scores=fixed(word_topic_scores),\n",
    "             word_topic_sp=fixed(word_topic_sp),\n",
    "             corpus=fixed(test_corpus),\n",
    "             doc_names=fixed(doc_names),\n",
    "             pre_trained_doc=fixed(pre_trained_doc),\n",
    "             purity_score=fixed(purity_score),\n",
    "             word_count=fixed(word_count),\n",
    "             only_doc_words=fixed(only_doc_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonnegative Matrix Factorization (NMF) method was first proposed by Lee and Seung paper1. The NMF is a method of decomposing a given nonnegative *X* matrix into *W* and *H* factors that contain nonnegative values. The value of the product of the two matrices obtained is approximately equal to the value of the decomposed matrix. In NMF, given a $W \\times K$ nonnegative matrix $X = \\left \\{ x_{\\nu, \\tau} \\right \\}$ where $\\nu = 1:V, i = 1:I \\text{ and } \\tau = 1:T$, we seek nonnegative matrices *W* and *H* such that\n",
    "\n",
    "\\begin{align*}\n",
    "x_{\\nu, \\tau} \\approx \\left [ WH \\right ]_{\\nu, \\tau} = \\sum_{i} w_{\\nu,i}h_{i,\\tau}\n",
    "\\end{align*}\n",
    "\n",
    "In this paper, we will refer to the $V\\times I$ matrix W as the *template matrix*, and $I\\times T$ matrix *H* the *excitation matrix*.\n",
    "\n",
    "\n",
    "$X = WH$\n",
    "\n",
    "$X$: documents X vocabulary. tf-idf is used for vocabulary.\n",
    "\n",
    "$W$: documents X topics. Calculate a seperate W for each Schwartz Value using corresponding H.\n",
    "\n",
    "$H$: topics X vocabulary. Calculate a seperate H for each Schwartz Value in the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Schwartz Word Scores\n",
    "\n",
    "* We have a fixed (learned) H matrix for each Schwartz Value that holds word-topic distribution.\n",
    "* We have W matrix for each document's Schwartz Values that holds topic-document distribution.\n",
    "* H matrix gave us an idea about the important words for each Schwartz Value (by providing some kind of weights for each word), but actually the weights of those words can be different for each document.\n",
    "* We propose two different methods to calculate those document spesific weighted word scores.\n",
    " * The summary of the approach is as follows: If a word appears in a document frequently (except stopwords) it can be considered as an important word for this document. If this words only occurs in a specific document then it is even more important. This is basically tf-idf which is our essential feature for this model. Moreover, if this word's tf-idf score obtained more from a specific topic rather than background info then we can accept it as an important indicator of this document and topic.\n",
    " * General equation: $X = WH$. Rather than directly using X or H, we figure in W to the calculation.   \n",
    " * Direct Schwartz: Multiply W and H only through the specific Schwartz Value Topics, excluding backgorund.\n",
    " * Purity Schwartz: Find the Schwartz Value purity of each word by taking the proportions of Direct Schwartz Score of this word to Direct Background Score (exclude Schwartz Value, include Backgroun) for each Schwartz Value. Then multiply this purity score with Direct Schwartz score to obtain Purity Schwartz Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schwartz Value WH carpimi:**\n",
    "\n",
    "Her Schwartz Value icin hangi kelimelerin daha onemli oldugunu anlamak icin H matrisini inceleyebiliriz. Her H matirisi bir Schwartz Value ve backgorund corpus icin birden cok sub-topic seviyesinde kelime dagilimlarini barindirmkata. Yani 3 sub-topic seviyesinde Universalism ornegi dusunursek, modelimiz tek bir cesit universalism degil de 3 farkli universalism cesidi ogrenmeye calisiyor. Bu da bize her universalism ceisidi icin farkli kelime onemleri sunuyor. Fakat universalism'le alakali en onemli kelimeler ne dendigi zaman sub-topic lerden bahsetmek yerine tek bir cati altinda toplamak genel resmi anlamayi cok daha kolaylastirmakta. \n",
    "\n",
    "Fakat burda sadece H matrisi uzerinden bir toplam yaptigggimiz zaman dokumanlarin hangi Universalism sub-topic iyle alakali oldugu bilgisini atmis olmaktayiz. Bu sebeple her dokumanin neden belirli bir Schwartz Value'ya yoneldigini gosteren kelimeleri highlight etmek icin dokumanlarin sub-topic seviyesinde yoneldikleri Schwartz Value degerleri (W) ile kelimelerin sub-topic seviyesinde gruplandigi Schwartz Value (H) degerlerini carpip topluyoruz. Sonuc olarak bir dokuman icin onu siniflandirmamizda en cok etkileyen kelimeleri Schwartz Value lar arasinda da karsilastirma yapabildigimiz bir skorlama vermis oluyor. \n",
    "\n",
    "**Schwartz Value Purity**\n",
    "\n",
    "Yukarida bahsedilen yontem butun Schwartz Value lar ve kelimeler arasinda goreceli bir karsilastirma yontemi saglamakta Fakat kelimeleri modellemekte kullandigimiz tf-idf ten gelen bir kelimenin bir dokumanda cokca gectigi icin onemi (skorunun) daha fazla gozukmekte. Bir yandan bunun etkisini azaltan ve ayni zamanda Schwartz Value purity konseptini uygulayan bir eklenti yapiyoruz. Kelimelerin her dokuman ve her Schwartz Value icin ne kadar saf oldugunu olcuyoruz. Ve bunu da buldugumuz skorla carpiyoruz. Boylece bu kelime sadece istedigimiz Schwartz Value da geciyorsa skoru gorecelei olarak artmis oluyor. Eger bu kelime cogunlukla istedigimiz Schwartz Value da degil de backgorund corpus ta geciorsa goreceli olarak skoru azalmis oluyor. Bu yontem ile aslinda istedigimiz Schwartz Value ile cok ilgili olmasa da sadece belirli dokumanlarda diger dokumanlara gore daha fazla gectigi icin skoru yuksek olan kelimelerin etkisini azaltmis oluyor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schwartz Value Word Scores\n",
    "\n",
    "Understanding the behavior of the model is important to make deductions from it. Our model uses words to match the Schwartz Values with documents. The training of the model forms the $H$ matrix, which holds the word-topic distributions for each Schwartz Value. If we have used a classic, simpler NMF model, then, to find the importance order of the words for each Schwartz Value, we can directly take the marginal of $H$ matrix for each topic. But, our model offers much more information with its sub-topics for each Schwartz Values and semi-supervised nature. \n",
    "\n",
    "#### Direct Word Scores\n",
    "\n",
    "Direct word score exploits the sub-topic structure of the model to come up with different word importance scores and orders for each document. $H$ matrix includes different word-distributions for each sub-topic of both a Schwartz Value and Background Corpus. In other words, if there is three sub-topics for \\textit{Power} Schwartz Value in the $H$ matrix, then our model learns three different concept for Power Schwartz Value which provides different word scores for each concept. However, it is more logical to present a  single set of word scores for a Schwartz Value rather than three different word score sets obtained from sub-topics.\n",
    "\n",
    "We can sum up values under sub-topics of H matrix to come up with a single word distribution with the cost of losing valuable sub-topic information. Thus, rather than finding a unified word-topic distribution for all documents, we calculate separate word scores for each document to highlight the important words that lead a document to be soft-classified as a specific Schwartz Value by dot product of documents' sub-topic level Schwartz Value scores ($W$) and words sub-topic level Schwartz Value scores ($H$). As a result, we obtain scores for all words under each Schwartz Value for each document that can be comparable with each other.\n",
    "\n",
    "\\begin{align*}\n",
    "DWS = \\sum_{i = 1}^{I/2} w_{\\nu,i}h_{i,\\tau}\n",
    "\\end{align*}\n",
    "\n",
    "#### Purity Word Scores\n",
    "\n",
    "\\begin{align*}\n",
    "DWS &= \\sum_{i = 1}^{I/2} w_{\\nu,i}h_{i,\\tau}\\\\\n",
    "BWS &= \\sum_{i = I/2}^{T} w_{\\nu,i}h_{i,\\tau}\\\\\n",
    "Purity &= \\frac{DWS}{DWS+BWS} \\\\\n",
    "PWS &= DWS * Purity\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores are multiplied by 100\n",
    "def calculate_word_topic_scores(pre_nmf_list, W_test_list, n_topics=3):\n",
    "    H_list = []\n",
    "    for pnmf in pre_nmf_list:\n",
    "        H_list.append(pnmf.components_)\n",
    "    H_list = np.asarray(H_list)\n",
    "    \n",
    "    # [value, doc, word]\n",
    "    word_topic_scores = []\n",
    "    word_background_scores = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        word_topic_scores.append(np.dot(W_test_list[i][:,:n_topics], H_list[i][:n_topics,:]))\n",
    "        word_background_scores.append(np.dot(W_test_list[i][:,n_topics:], H_list[i][n_topics:,:]))\n",
    "        \n",
    "    word_topic_scores = np.asarray(word_topic_scores)\n",
    "    word_background_scores = np.asarray(word_background_scores)\n",
    "    \n",
    "    word_topic_purity = np.nan_to_num(np.divide(word_topic_scores,word_topic_scores+word_background_scores))\n",
    "    word_topic_sp = word_topic_scores*word_topic_purity\n",
    "    \n",
    "    word_topic_scores *= 100\n",
    "    word_topic_sp *= 100\n",
    "    \n",
    "    return word_topic_scores, word_topic_sp\n",
    "\n",
    "def find_top_word_scores(pre_tfidf_vectorizer, word_topic, word_count, test_corpusPP, only_doc_words):\n",
    "    word_list = []\n",
    "    feature_names = pre_tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    tcpp = test_corpusPP.split()\n",
    "    \n",
    "    for theme in range(10):\n",
    "        tmp_list = []\n",
    "        i = 0 \n",
    "        for idx in list(reversed(word_topic[theme].argsort())):\n",
    "            if i == word_count:\n",
    "                break\n",
    "            if not(only_doc_words and (feature_names[idx] not in tcpp)):\n",
    "                tmp_list.append((feature_names[idx], np.round(word_topic[theme][idx], 3)))\n",
    "            else:\n",
    "                i -= 1\n",
    "            i += 1\n",
    "        word_list.append(tmp_list)\n",
    "    return word_list\n",
    "\n",
    "def schwartz_word_scores(doc, W_test_norm, test_corpusPP, word_topic_scores, word_topic_sp, pre_tfidf_vectorizer, purity_score, word_count, only_doc_words):\n",
    "    if purity_score:\n",
    "        top_scores = find_top_word_scores(pre_tfidf_vectorizer, word_topic_sp[:,doc,:], word_count, test_corpusPP[doc], only_doc_words)\n",
    "    else:\n",
    "        top_scores = find_top_word_scores(pre_tfidf_vectorizer, word_topic_scores[:,doc,:], word_count, test_corpusPP[doc], only_doc_words)\n",
    "    \n",
    "    schwartz_word_score = []\n",
    "    schwartz_W_test = []\n",
    "    for sch in schwartz:\n",
    "        schwartz_word_score.append(top_scores[categories.index(sch)])\n",
    "        schwartz_W_test.append((sch.upper(), np.round(W_test_norm[doc][categories.index(sch)], 3)))\n",
    "        \n",
    "    df_list = []\n",
    "    for i, a in enumerate(schwartz_word_score):\n",
    "        df_list.append(pd.DataFrame([schwartz_W_test[i]]+a, columns=[schwartz[i]+\" - word\", schwartz[i]+\" - score\"]))\n",
    "    score_df = pd.concat(df_list, axis=1)\n",
    "    \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Pretrained Model's Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nmf2_pretrained.p** or **nmf2_pretrained_pruned.p** includes pretrained NMF model generated using **Semi-Supervised-NMF-train-v2.ipynb** notebook. It has the nmf model and tfidf_vectorizer.\n",
    "\n",
    "for the details of purned version see also **\"OMTermz HZ.ipynb\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_words(pre_trained_doc, word_count, anti=0):\n",
    "    pre_nmf_list, pre_tfidf_vectorizer = pickle.load( open( pre_trained_doc, \"rb\" ) )\n",
    "    \n",
    "    word_list = []\n",
    "    feature_names = pre_tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    for theme in range(10):\n",
    "        word_topic = cumulate_W(pre_nmf_list[theme].components_.T,3).T[anti]\n",
    "        tmp_list = []\n",
    "        for i, idx in enumerate(list(reversed(word_topic.argsort()))):\n",
    "            if i == word_count:\n",
    "                break\n",
    "            tmp_list.append((feature_names[idx], np.round(word_topic[idx], 3)))\n",
    "        word_list.append(tmp_list)\n",
    "    \n",
    "    schwartz_word_score = []\n",
    "    for sch in schwartz:\n",
    "        schwartz_word_score.append(word_list[categories.index(sch)])\n",
    "        \n",
    "    df_list = []\n",
    "    for i, a in enumerate(schwartz_word_score):\n",
    "        df_list.append(pd.DataFrame(a, columns=[schwartz[i]+\" - word\", schwartz[i]+\" - score\"]))\n",
    "    score_df = pd.concat(df_list, axis=1)\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "def export_pretrained_excel(pre_trained_doc, filepath, word_count=-1, anti=0):\n",
    "    df = get_pretrained_words(pre_trained_doc, word_count, anti)\n",
    "    df.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model:\n",
      "\u001b[96m\u001b[1muniversalism\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mcritical use first plant international\n",
      "\u001b[1mTopic #1: \u001b[0mhelp law day general world\n",
      "\u001b[1mTopic #2: \u001b[0moften reason system term example\n",
      "\n",
      "\u001b[96m\u001b[1mhedonism\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0msense system suggest say personality\n",
      "\u001b[1mTopic #1: \u001b[0msadness positive regret shock rejection\n",
      "\u001b[1mTopic #2: \u001b[0mpeople still must western thus\n",
      "\n",
      "\u001b[96m\u001b[1machievement\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mplease merely citation procedure value\n",
      "\u001b[1mTopic #1: \u001b[0msocial lead india relation important\n",
      "\u001b[1mTopic #2: \u001b[0mtheory mark occur suppress obtain\n",
      "\n",
      "\u001b[96m\u001b[1mpower\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0malexandre form along separately tyranny\n",
      "\u001b[1mTopic #1: \u001b[0magency one liability draw service\n",
      "\u001b[1mTopic #2: \u001b[0mput italian task mean interest\n",
      "\n",
      "\u001b[96m\u001b[1mself-direction\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mquestion late use beard order\n",
      "\u001b[1mTopic #1: \u001b[0msituation quite invoke technology increasingly\n",
      "\u001b[1mTopic #2: \u001b[0mpublic attractive provide proper katanga\n",
      "\n",
      "\u001b[96m\u001b[1mbenevolence\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mprovide tradition thus think servant\n",
      "\u001b[1mTopic #1: \u001b[0mpower might also self truthiness\n",
      "\u001b[1mTopic #2: \u001b[0mrachel mazda utility still false\n",
      "\n",
      "\u001b[96m\u001b[1mconformity\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mstatus vary show suppletive boundary\n",
      "\u001b[1mTopic #1: \u001b[0mshow trace upon suggest unsourced\n",
      "\u001b[1mTopic #2: \u001b[0mrefer morality tell lord method\n",
      "\n",
      "\u001b[96m\u001b[1mtradition\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0msecret objectively strive sophrosyne signify\n",
      "\u001b[1mTopic #1: \u001b[0marabic thinker experiment lose discrimination\n",
      "\u001b[1mTopic #2: \u001b[0mtheme past theology kant state\n",
      "\n",
      "\u001b[96m\u001b[1mstimulation\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mproblem magic mass exclude pattern\n",
      "\u001b[1mTopic #1: \u001b[0mreach gridiron term instrument similar\n",
      "\u001b[1mTopic #2: \u001b[0mptolemaic sahara likely evidence occur\n",
      "\n",
      "\u001b[96m\u001b[1msecurity\u001b[0m\n",
      "\u001b[1mTopic #0: \u001b[0mone outbreak research sacrifice may\n",
      "\u001b[1mTopic #1: \u001b[0mindividual thus imply expert oil\n",
      "\u001b[1mTopic #2: \u001b[0mhealthcare interest regulation emotion team\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_trained_doc = \"nmf2_pretrained_pruned_lem.p\"\n",
    "print_training_topics(pre_trained_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are cumulated word-topic values directly obtained from the pretrained word-topic matrix (H). The reason of higher values in universalism or hedonism is probably unbalanced distribution of training documents. (Universalism and Hedonism have much more training documents than others)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universalism - word</th>\n",
       "      <th>universalism - score</th>\n",
       "      <th>benevolence - word</th>\n",
       "      <th>benevolence - score</th>\n",
       "      <th>conformity - word</th>\n",
       "      <th>conformity - score</th>\n",
       "      <th>tradition - word</th>\n",
       "      <th>tradition - score</th>\n",
       "      <th>security - word</th>\n",
       "      <th>security - score</th>\n",
       "      <th>power - word</th>\n",
       "      <th>power - score</th>\n",
       "      <th>achievement - word</th>\n",
       "      <th>achievement - score</th>\n",
       "      <th>hedonism - word</th>\n",
       "      <th>hedonism - score</th>\n",
       "      <th>stimulation - word</th>\n",
       "      <th>stimulation - score</th>\n",
       "      <th>self-direction - word</th>\n",
       "      <th>self-direction - score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>help</td>\n",
       "      <td>1.515</td>\n",
       "      <td>think</td>\n",
       "      <td>0.795</td>\n",
       "      <td>show</td>\n",
       "      <td>1.200</td>\n",
       "      <td>arabic</td>\n",
       "      <td>0.502</td>\n",
       "      <td>one</td>\n",
       "      <td>0.764</td>\n",
       "      <td>one</td>\n",
       "      <td>0.541</td>\n",
       "      <td>social</td>\n",
       "      <td>1.125</td>\n",
       "      <td>say</td>\n",
       "      <td>1.225</td>\n",
       "      <td>problem</td>\n",
       "      <td>0.557</td>\n",
       "      <td>use</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>often</td>\n",
       "      <td>1.458</td>\n",
       "      <td>power</td>\n",
       "      <td>0.755</td>\n",
       "      <td>upon</td>\n",
       "      <td>0.804</td>\n",
       "      <td>theme</td>\n",
       "      <td>0.485</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>0.745</td>\n",
       "      <td>form</td>\n",
       "      <td>0.502</td>\n",
       "      <td>use</td>\n",
       "      <td>0.765</td>\n",
       "      <td>suggest</td>\n",
       "      <td>1.213</td>\n",
       "      <td>reach</td>\n",
       "      <td>0.541</td>\n",
       "      <td>question</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world</td>\n",
       "      <td>1.423</td>\n",
       "      <td>use</td>\n",
       "      <td>0.724</td>\n",
       "      <td>state</td>\n",
       "      <td>0.713</td>\n",
       "      <td>secret</td>\n",
       "      <td>0.479</td>\n",
       "      <td>individual</td>\n",
       "      <td>0.684</td>\n",
       "      <td>state</td>\n",
       "      <td>0.496</td>\n",
       "      <td>theory</td>\n",
       "      <td>0.762</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.183</td>\n",
       "      <td>gridiron</td>\n",
       "      <td>0.521</td>\n",
       "      <td>late</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>1.313</td>\n",
       "      <td>provide</td>\n",
       "      <td>0.715</td>\n",
       "      <td>status</td>\n",
       "      <td>0.638</td>\n",
       "      <td>objectively</td>\n",
       "      <td>0.473</td>\n",
       "      <td>interest</td>\n",
       "      <td>0.631</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.493</td>\n",
       "      <td>important</td>\n",
       "      <td>0.762</td>\n",
       "      <td>selfconfidence</td>\n",
       "      <td>1.158</td>\n",
       "      <td>term</td>\n",
       "      <td>0.485</td>\n",
       "      <td>situation</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>use</td>\n",
       "      <td>1.280</td>\n",
       "      <td>also</td>\n",
       "      <td>0.714</td>\n",
       "      <td>refer</td>\n",
       "      <td>0.613</td>\n",
       "      <td>theology</td>\n",
       "      <td>0.472</td>\n",
       "      <td>thus</td>\n",
       "      <td>0.561</td>\n",
       "      <td>agency</td>\n",
       "      <td>0.490</td>\n",
       "      <td>term</td>\n",
       "      <td>0.742</td>\n",
       "      <td>shock</td>\n",
       "      <td>1.124</td>\n",
       "      <td>instrument</td>\n",
       "      <td>0.467</td>\n",
       "      <td>people</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>1.261</td>\n",
       "      <td>tradition</td>\n",
       "      <td>0.702</td>\n",
       "      <td>use</td>\n",
       "      <td>0.606</td>\n",
       "      <td>past</td>\n",
       "      <td>0.446</td>\n",
       "      <td>small</td>\n",
       "      <td>0.550</td>\n",
       "      <td>thus</td>\n",
       "      <td>0.476</td>\n",
       "      <td>lead</td>\n",
       "      <td>0.678</td>\n",
       "      <td>people</td>\n",
       "      <td>1.063</td>\n",
       "      <td>ptolemaic</td>\n",
       "      <td>0.284</td>\n",
       "      <td>public</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>law</td>\n",
       "      <td>1.237</td>\n",
       "      <td>thus</td>\n",
       "      <td>0.688</td>\n",
       "      <td>trace</td>\n",
       "      <td>0.589</td>\n",
       "      <td>state</td>\n",
       "      <td>0.442</td>\n",
       "      <td>imply</td>\n",
       "      <td>0.518</td>\n",
       "      <td>alexandre</td>\n",
       "      <td>0.456</td>\n",
       "      <td>value</td>\n",
       "      <td>0.678</td>\n",
       "      <td>sense</td>\n",
       "      <td>1.052</td>\n",
       "      <td>sahara</td>\n",
       "      <td>0.274</td>\n",
       "      <td>technology</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>social</td>\n",
       "      <td>1.161</td>\n",
       "      <td>might</td>\n",
       "      <td>0.674</td>\n",
       "      <td>vary</td>\n",
       "      <td>0.565</td>\n",
       "      <td>thinker</td>\n",
       "      <td>0.405</td>\n",
       "      <td>may</td>\n",
       "      <td>0.512</td>\n",
       "      <td>tyranny</td>\n",
       "      <td>0.454</td>\n",
       "      <td>please</td>\n",
       "      <td>0.633</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>1.014</td>\n",
       "      <td>magic</td>\n",
       "      <td>0.271</td>\n",
       "      <td>quite</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>way</td>\n",
       "      <td>1.149</td>\n",
       "      <td>term</td>\n",
       "      <td>0.642</td>\n",
       "      <td>two</td>\n",
       "      <td>0.550</td>\n",
       "      <td>sophrosyne</td>\n",
       "      <td>0.391</td>\n",
       "      <td>regulation</td>\n",
       "      <td>0.501</td>\n",
       "      <td>put</td>\n",
       "      <td>0.420</td>\n",
       "      <td>message</td>\n",
       "      <td>0.633</td>\n",
       "      <td>system</td>\n",
       "      <td>0.985</td>\n",
       "      <td>mass</td>\n",
       "      <td>0.259</td>\n",
       "      <td>invoke</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>term</td>\n",
       "      <td>1.140</td>\n",
       "      <td>place</td>\n",
       "      <td>0.621</td>\n",
       "      <td>unsourced</td>\n",
       "      <td>0.546</td>\n",
       "      <td>kant</td>\n",
       "      <td>0.389</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.490</td>\n",
       "      <td>liability</td>\n",
       "      <td>0.410</td>\n",
       "      <td>within</td>\n",
       "      <td>0.601</td>\n",
       "      <td>use</td>\n",
       "      <td>0.965</td>\n",
       "      <td>evidence</td>\n",
       "      <td>0.226</td>\n",
       "      <td>order</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  universalism - word  universalism - score benevolence - word  \\\n",
       "0                help                 1.515              think   \n",
       "1               often                 1.458              power   \n",
       "2               world                 1.423                use   \n",
       "3               state                 1.313            provide   \n",
       "4                 use                 1.280               also   \n",
       "5                 one                 1.261          tradition   \n",
       "6                 law                 1.237               thus   \n",
       "7              social                 1.161              might   \n",
       "8                 way                 1.149               term   \n",
       "9                term                 1.140              place   \n",
       "\n",
       "   benevolence - score conformity - word  conformity - score tradition - word  \\\n",
       "0                0.795              show               1.200           arabic   \n",
       "1                0.755              upon               0.804            theme   \n",
       "2                0.724             state               0.713           secret   \n",
       "3                0.715            status               0.638      objectively   \n",
       "4                0.714             refer               0.613         theology   \n",
       "5                0.702               use               0.606             past   \n",
       "6                0.688             trace               0.589            state   \n",
       "7                0.674              vary               0.565          thinker   \n",
       "8                0.642               two               0.550       sophrosyne   \n",
       "9                0.621         unsourced               0.546             kant   \n",
       "\n",
       "   tradition - score security - word  security - score power - word  \\\n",
       "0              0.502             one             0.764          one   \n",
       "1              0.485      healthcare             0.745         form   \n",
       "2              0.479      individual             0.684        state   \n",
       "3              0.473        interest             0.631         mean   \n",
       "4              0.472            thus             0.561       agency   \n",
       "5              0.446           small             0.550         thus   \n",
       "6              0.442           imply             0.518    alexandre   \n",
       "7              0.405             may             0.512      tyranny   \n",
       "8              0.391      regulation             0.501          put   \n",
       "9              0.389          expert             0.490    liability   \n",
       "\n",
       "   power - score achievement - word  achievement - score hedonism - word  \\\n",
       "0          0.541             social                1.125             say   \n",
       "1          0.502                use                0.765         suggest   \n",
       "2          0.496             theory                0.762        positive   \n",
       "3          0.493          important                0.762  selfconfidence   \n",
       "4          0.490               term                0.742           shock   \n",
       "5          0.476               lead                0.678          people   \n",
       "6          0.456              value                0.678           sense   \n",
       "7          0.454             please                0.633       sometimes   \n",
       "8          0.420            message                0.633          system   \n",
       "9          0.410             within                0.601             use   \n",
       "\n",
       "   hedonism - score stimulation - word  stimulation - score  \\\n",
       "0             1.225            problem                0.557   \n",
       "1             1.213              reach                0.541   \n",
       "2             1.183           gridiron                0.521   \n",
       "3             1.158               term                0.485   \n",
       "4             1.124         instrument                0.467   \n",
       "5             1.063          ptolemaic                0.284   \n",
       "6             1.052             sahara                0.274   \n",
       "7             1.014              magic                0.271   \n",
       "8             0.985               mass                0.259   \n",
       "9             0.965           evidence                0.226   \n",
       "\n",
       "  self-direction - word  self-direction - score  \n",
       "0                   use                   0.790  \n",
       "1              question                   0.612  \n",
       "2                  late                   0.564  \n",
       "3             situation                   0.539  \n",
       "4                people                   0.530  \n",
       "5                public                   0.497  \n",
       "6            technology                   0.488  \n",
       "7                 quite                   0.471  \n",
       "8                invoke                   0.461  \n",
       "9                 order                   0.460  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pretrained_words(pre_trained_doc, word_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exports all word-score pairs in vocabulary (~33000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_pretrained_excel(pre_trained_doc, filepath='pretrained_words.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Different Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding two example documents to the test_corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pope ted talk, https://www.ted.com/speakers/pope_francis\n",
    "# US Department of Defense, https://www.defense.gov/About/\n",
    "doc_names = [\"pope.txt\", \"dod.txt\", \"https://www.nationalgeographic.com/science/space/solar-system/earth/\", \"https://sadasd\", \"asdasd\"]\n",
    "#doc_names = [\"pope.txt\", \"dod.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_corpus_docs(doc_names, test_corpus, insigth_api_key):\n",
    "    for doc in doc_names:\n",
    "        if re.match(\"^(http|https)://\", doc) is None:\n",
    "            add_corpus_txt(doc, test_corpus)\n",
    "        else:\n",
    "            add_corpus_url(doc, insigth_api_key, test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling a website using InSight API and adding its text to test_corpus.\n",
    "\n",
    "Always check the text, added to the corpus via add_corpus_url. Because websites can have unexpected embedded texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Not Found - https://sadasd\n",
      "File not found - asdasd\n"
     ]
    }
   ],
   "source": [
    "test_corpus = []\n",
    "insigth_api_key = \"\" #needs to be filled\n",
    "add_corpus_docs(doc_names, test_corpus, insigth_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix bad wording:  0.0029888153076171875 s\n",
      "Tokenize:  0.008988618850708008 s\n",
      "Remove stopwords and Lemmatize:  0.01500082015991211 s\n",
      "\n",
      "Fix bad wording:  0.0019941329956054688 s\n",
      "Tokenize:  0.0030221939086914062 s\n",
      "Remove stopwords and Lemmatize:  0.006952524185180664 s\n",
      "\n",
      "Fix bad wording:  0.0009968280792236328 s\n",
      "Tokenize:  0.000997304916381836 s\n",
      "Remove stopwords and Lemmatize:  0.0030176639556884766 s\n",
      "\n",
      "Fix bad wording:  0.0 s\n",
      "Tokenize:  0.0 s\n",
      "Remove stopwords and Lemmatize:  0.0 s\n",
      "\n",
      "Fix bad wording:  0.0 s\n",
      "Tokenize:  0.0 s\n",
      "Remove stopwords and Lemmatize:  0.0 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean Corpus\n",
    "test_corpusPP = [tp.clean_text(doc) for doc in test_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonym Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = 500\n",
    "synonym_count = 20\n",
    "similarity_span = 10\n",
    "\n",
    "df_words = get_pretrained_words(pre_trained_doc, word_count)\n",
    "cols = df_words.columns\n",
    "for c_id in range(1, len(cols), 2):\n",
    "    df_words.drop(columns=[cols[c_id]], inplace=True)\n",
    "synonyms_df = syn.important_train_synonyms(df_words, word_count, synonym_count, similarity_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_nmf_list, pre_tfidf_vectorizer = pickle.load( open( pre_trained_doc, \"rb\" ) )\n",
    "trained_vocabulary = pre_tfidf_vectorizer.get_feature_names()\n",
    "word_replacements = syn.find_doc_word_synonyms(test_corpusPP, synonyms_df, trained_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model for the test_corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NMF for universalism\n",
      "Fitting NMF for hedonism\n",
      "Fitting NMF for achievement\n",
      "Fitting NMF for power\n",
      "Fitting NMF for self-direction\n",
      "Fitting NMF for benevolence\n",
      "Fitting NMF for conformity\n",
      "Fitting NMF for tradition\n",
      "Fitting NMF for stimulation\n",
      "Fitting NMF for security\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "W_test_norm, W_test_list, tfidf_test = evaluate_test_corpus(pre_trained_doc, test_corpusPP, word_replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for test_corpus\n",
    "\n",
    "(All values are multiplied by 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When \"only_doc_words\" parameter set to True, the table will only show words from the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1967e0ec6e4979a88d9b1cfc57e4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='doc', max=4), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_interactive_test_results(W_test_norm, W_test_list, test_corpus, test_corpusPP, doc_names, pre_trained_doc, purity_score = False, word_count = 10, only_doc_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>universalism</th>\n",
       "      <th>benevolence</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "      <th>security</th>\n",
       "      <th>power</th>\n",
       "      <th>achievement</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>self-direction</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pope.txt</td>\n",
       "      <td>19.643708</td>\n",
       "      <td>62.965842</td>\n",
       "      <td>77.557248</td>\n",
       "      <td>38.481883</td>\n",
       "      <td>17.296200</td>\n",
       "      <td>43.970087</td>\n",
       "      <td>44.737977</td>\n",
       "      <td>51.584388</td>\n",
       "      <td>41.782835</td>\n",
       "      <td>49.243369</td>\n",
       "      <td>Good evening  or, good morning, I am not su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dod.txt</td>\n",
       "      <td>88.126194</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>10.455854</td>\n",
       "      <td>28.390529</td>\n",
       "      <td>78.130468</td>\n",
       "      <td>60.376097</td>\n",
       "      <td>32.600423</td>\n",
       "      <td>4.951889</td>\n",
       "      <td>32.506595</td>\n",
       "      <td>32.863906</td>\n",
       "      <td>\\nOn behalf of the Secretary of Defense and De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nationalgeographic.com/science/spa...</td>\n",
       "      <td>85.302025</td>\n",
       "      <td>11.082767</td>\n",
       "      <td>24.768660</td>\n",
       "      <td>5.908274</td>\n",
       "      <td>60.309391</td>\n",
       "      <td>64.362547</td>\n",
       "      <td>4.187538</td>\n",
       "      <td>31.662962</td>\n",
       "      <td>91.641003</td>\n",
       "      <td>52.770443</td>\n",
       "      <td>Earth, our home planet, is the only planet in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sadasd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asdasd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  universalism  \\\n",
       "0                                           pope.txt     19.643708   \n",
       "1                                            dod.txt     88.126194   \n",
       "2  https://www.nationalgeographic.com/science/spa...     85.302025   \n",
       "3                                     https://sadasd      0.000000   \n",
       "4                                             asdasd      0.000000   \n",
       "\n",
       "   benevolence  conformity  tradition   security      power  achievement  \\\n",
       "0    62.965842   77.557248  38.481883  17.296200  43.970087    44.737977   \n",
       "1     0.003423   10.455854  28.390529  78.130468  60.376097    32.600423   \n",
       "2    11.082767   24.768660   5.908274  60.309391  64.362547     4.187538   \n",
       "3     0.000000    0.000000   0.000000   0.000000   0.000000     0.000000   \n",
       "4     0.000000    0.000000   0.000000   0.000000   0.000000     0.000000   \n",
       "\n",
       "    hedonism  stimulation  self-direction  \\\n",
       "0  51.584388    41.782835       49.243369   \n",
       "1   4.951889    32.506595       32.863906   \n",
       "2  31.662962    91.641003       52.770443   \n",
       "3   0.000000     0.000000        0.000000   \n",
       "4   0.000000     0.000000        0.000000   \n",
       "\n",
       "                                                Text  \n",
       "0  Good evening  or, good morning, I am not su...  \n",
       "1  \\nOn behalf of the Secretary of Defense and De...  \n",
       "2  Earth, our home planet, is the only planet in ...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = export_to_excel(W_test_norm, test_corpus, doc_names, filepath = 'output.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>universalism</th>\n",
       "      <th>benevolence</th>\n",
       "      <th>conformity</th>\n",
       "      <th>tradition</th>\n",
       "      <th>security</th>\n",
       "      <th>power</th>\n",
       "      <th>achievement</th>\n",
       "      <th>hedonism</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>self-direction</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pope.txt</td>\n",
       "      <td>19.643708</td>\n",
       "      <td>62.965842</td>\n",
       "      <td>77.557248</td>\n",
       "      <td>38.481883</td>\n",
       "      <td>17.296200</td>\n",
       "      <td>43.970087</td>\n",
       "      <td>44.737977</td>\n",
       "      <td>51.584388</td>\n",
       "      <td>41.782835</td>\n",
       "      <td>49.243369</td>\n",
       "      <td>Good evening  or, good morning, I am not su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dod.txt</td>\n",
       "      <td>88.126194</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>10.455854</td>\n",
       "      <td>28.390529</td>\n",
       "      <td>78.130468</td>\n",
       "      <td>60.376097</td>\n",
       "      <td>32.600423</td>\n",
       "      <td>4.951889</td>\n",
       "      <td>32.506595</td>\n",
       "      <td>32.863906</td>\n",
       "      <td>\\nOn behalf of the Secretary of Defense and De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nationalgeographic.com/science/spa...</td>\n",
       "      <td>85.302025</td>\n",
       "      <td>11.082767</td>\n",
       "      <td>24.768660</td>\n",
       "      <td>5.908274</td>\n",
       "      <td>60.309391</td>\n",
       "      <td>64.362547</td>\n",
       "      <td>4.187538</td>\n",
       "      <td>31.662962</td>\n",
       "      <td>91.641003</td>\n",
       "      <td>52.770443</td>\n",
       "      <td>Earth, our home planet, is the only planet in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sadasd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asdasd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  universalism  \\\n",
       "0                                           pope.txt     19.643708   \n",
       "1                                            dod.txt     88.126194   \n",
       "2  https://www.nationalgeographic.com/science/spa...     85.302025   \n",
       "3                                     https://sadasd      0.000000   \n",
       "4                                             asdasd      0.000000   \n",
       "\n",
       "   benevolence  conformity  tradition   security      power  achievement  \\\n",
       "0    62.965842   77.557248  38.481883  17.296200  43.970087    44.737977   \n",
       "1     0.003423   10.455854  28.390529  78.130468  60.376097    32.600423   \n",
       "2    11.082767   24.768660   5.908274  60.309391  64.362547     4.187538   \n",
       "3     0.000000    0.000000   0.000000   0.000000   0.000000     0.000000   \n",
       "4     0.000000    0.000000   0.000000   0.000000   0.000000     0.000000   \n",
       "\n",
       "    hedonism  stimulation  self-direction  \\\n",
       "0  51.584388    41.782835       49.243369   \n",
       "1   4.951889    32.506595       32.863906   \n",
       "2  31.662962    91.641003       52.770443   \n",
       "3   0.000000     0.000000        0.000000   \n",
       "4   0.000000     0.000000        0.000000   \n",
       "\n",
       "                                                Text  \n",
       "0  Good evening  or, good morning, I am not su...  \n",
       "1  \\nOn behalf of the Secretary of Defense and De...  \n",
       "2  Earth, our home planet, is the only planet in ...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = export_to_csv(W_test_norm, test_corpus, doc_names, filepath = 'output.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# When word_count is -1, it exports all the words\n",
    "# When only_doc_words is set to True, it exports only the words used in the documents\n",
    "\n",
    "# if you want proper document names in the output file change 'doc_names' list.\n",
    "export_word_scores_excel(W_test_norm, W_test_list, doc_names, pre_trained_doc, filepath = 'ssnmf_words.xlsx', purity_score=False, word_count=-1, only_doc_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports tf-idf scores of the words that are used in the documents as a single xlsx file\n",
    "export_doc_tfidf_scores(tfidf_test, doc_names, pre_trained_doc, filepath = 'tfidf_docs.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
